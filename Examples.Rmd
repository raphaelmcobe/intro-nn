---
title: "Neural Net Package Examples"
author: "Raphael Cobe"
date: "12/2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, echo=T}
library("neuralnet")
```
Going to create a neural network to perform square rooting
Type ?neuralnet for more information on the neuralnet library

Generate 50 random numbers uniformly distributed between 0 and 100
And store them as a dataframe
```{r, echo=T}
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
```
Column bind the data into one variable
```{r, echo=T}
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
```
Train the neural network
Going to have 10 hidden layers
Threshold is a numeric value specifying the threshold for the partial
derivatives of the error function as stopping criteria.
```{r, echo=T}
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```
Plot the neural network
```{r, echo=T}
plot(net.sqrt, rep = "best")
dev.off()
```

Test the neural network on some training data
```{r, echo=T}
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
```
Lets see what properties net.sqrt has
```{r, echo=T}
ls(net.results)
```
Lets see the results
```{r, echo=T}
print(net.results$net.result)
```
Lets display a better version of the results
```{r, echo=T}
cleanoutput <- cbind(testdata,sqrt(testdata),
                     as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```



# `sin` function


Generate random data and the dependent variable

```{r, echo=T}
x <- sort(runif(50, min = 0, max = 4*pi))
y <- sin(x)

data <- cbind(x,y)
```


Create the neural network responsible for the sin function
```{r, echo=T}
library(neuralnet)
sin.nn <- neuralnet(y ~ x, data = data, hidden = 5, stepmax = 100000, learningrate = 10e-6,  
                    act.fct = 'logistic', err.fct = 'sse', linear.output = T)

```

Visualize the neural network

```{r, echo=T}
plot(sin.nn, rep="best")
dev.off()
```

Generate data for the prediction of the using the neural net;

```{r, echo=T}
testdata<- as.data.frame(runif(10, min=0, max=(4*pi)))
testdata
```

Calculate the real value using the `sin` function

```{r}
testdata.result <- sin(testdata)
```

Make the prediction

```{r}
sin.nn.result <- compute(sin.nn, testdata)
sin.nn.result$net.result
```


Compare with the real values:

```{r}
better <- cbind(testdata, sin.nn.result$net.result, testdata.result, (sin.nn.result$net.result-testdata.result))
colnames(better) <- c("Input", "NN Result", "Result", "Error")

better
```

Calculate the RMSE:
```{r}
library(Metrics)
rmse(better$Result, better$`NN Result`)
```



Plot the results:
```{r}
plot(x,y)
plot(sin, 0, (4*pi), add=T)
x1 <- seq(0, 4*pi, by=0.1)
lines(x1, compute(sin.nn, data.frame(x=x1))$net.result, col="green")
```


# A classification problem

Using the `mtcars` dataset:
```{r}
data(mtcars)
mtcars.data <- mtcars
```

Check what is inside the dataset:

```{r}
head(mtcars.data)
```

Change the dataset so we are able to predict classes:

```{r}
mtcars.data$automatic <- mtcars.data$am=="1"
mtcars.data$manual <- mtcars.data$am=="0"
```


Separate into train and test data:

```{r}
train <- sample(x = nrow(mtcars.data), size = nrow(mtcars.data)*0.7)
train
```

```{r}
mtcars.train <- mtcars.data[train,]
mtcars.valid <- mtcars.data[-train,]
print(nrow(mtcars.train))
print(nrow(mtcars.valid))
```

Build the Neural Network for the classification:

```{r}
nn <- neuralnet(automatic+manual ~ mpg + disp, data=mtcars.train, hidden = 3, 
                err.fct = "ce", linear.output = F, lifesign = "minimal", stepmax = 1000000)
```

Let's check the neural network that we just built

```{r}
plot(nn, rep = "best")
```



Let's try to make the prediction:

```{r}
comp <- compute(nn, mtcars.valid[,c(1,3)])
pred.weights <- comp$net.result
idx <- apply(pred.weights, 1, which.max)
table(idx, mtcars.valid$am)
```









## The Challenge

Using the `iris` dataset
```{r}
data(iris)
iris.dataset <- iris
```

Check what is inside the dataset:

```{r}
head(iris.dataset)
```

Change the dataset so we are able to predict classes:

```{r}
iris.dataset$setosa <- iris.dataset$Species=="setosa"
iris.dataset$virginica = iris.dataset$Species == "virginica"
iris.dataset$versicolor = iris.dataset$Species == "versicolor"
```


Separate into train and test data:

```{r}
train <- sample(x = nrow(iris.dataset), size = nrow(iris)*0.5)
train
```

```{r}
iristrain <- iris.dataset[train,]
irisvalid <- iris.dataset[-train,]
print(nrow(iristrain))
print(nrow(irisvalid))
```

Build the Neural Network for the classification:

```{r}
nn <- neuralnet(setosa+versicolor+virginica ~ Sepal.Length + Sepal.Width, data=iristrain, hidden=3, 
                err.fct = "ce", linear.output = F, lifesign = "minimal", stepmax = 1000000)
```

Let's check the neural network that we just built

```{r}
# plot(nn, rep="best")
```


Let's try to make the prediction:

```{r}
comp <- compute(nn, irisvalid[-3:-8])
pred.weights <- comp$net.result
idx <- apply(pred.weights, 1, which.max)
pred <- c('setosa', 'versicolor', 'virginica')[idx]
table(pred, irisvalid$Species)
```


# AND operation
```{r}
AND <- c(rep(0,3),1)
OR <- c(0,rep(1,3))
binary.data <- data.frame(expand.grid(c(0,1), c(0,1)), AND)
print(net <- neuralnet(AND~Var1+Var2, binary.data, hidden=0, rep=10, err.fct="ce", linear.output=FALSE))
```

Now to validate the predictions:

```{r}
input <- data.frame(expand.grid(c(0,1), c(0,1)))
net.results <- compute(net, input)
cbind(round(net.results$net.result), AND)
```

